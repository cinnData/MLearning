{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - The spam filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we develop a **spam filter** based on a **decision tree**. A spam filter is a model which classifies e-mail messages as either spam or non-spam, using a collection of **numeric features** such as the frequency of certain words or characters. A differential trait of this example is that, in a spam filter, the **false positive rate**, that is, the proportion of non-spam messages wrongly classified as spam, must be very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `spam.csv` contains data on 4,601 e-mail messages. Among these messages, 1,813 have been classified as spam. The data were gathered at Hewlett-Packard by merging: (a) a collection of spam e-mail from the company postmaster and the individuals who had filed spam, and (b) a collection of non-spam e-mail, extracted from filed work and personal e-mail.\n",
    "\n",
    "The variables are:\n",
    "\n",
    "* 48 numeric features whose names start with `word_`, followed by a word. They indicate the frequency, in percentage scale, with which that word appears in the message. Example: for a particular message, a value 0.21 for `word_make` means that 0.21% of the words in the message match the word 'make'.\n",
    "\n",
    "* 3 numeric features indicating, respectively, the average length of uninterrupted sequences of capital letters (`cap_ave`), the length of the longest uninterrupted sequence of capital letters (`cap_long`) and the total number of capital letters in the message (`cap_total`).\n",
    "\n",
    "* A dummy indicating whether that e-mail message is spam (`spam`).\n",
    "\n",
    "Source: Hewlett-Packard. Taken from T Hastie, R Tibshirani & JH Friedman (2001), *The Elements of Statistical Learning*, Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in other examples, I import the data, from a remote CSV file, to a **structured array**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/cinnData/MLearning/main/Data/'\n",
    "fname = path + 'spam.csv'\n",
    "data = np.genfromtxt(fname, delimiter=',', names=True, dtype=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` should be a structured array with 4,061 rows. Indeed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I check only the first row, because the source file has 52 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0., 0.64, 0.64, 0., 0.32, 0., 0., 0., 0., 0., 0., 0.64, 0., 0., 0., 0.32, 0., 1.29, 1.93, 0., 0.96, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3.756, 61, 278, 1)],\n",
       "      dtype=[('word_make', '<f8'), ('word_address', '<f8'), ('word_all', '<f8'), ('word_3d', '<f8'), ('word_our', '<f8'), ('word_over', '<f8'), ('word_remove', '<f8'), ('word_internet', '<f8'), ('word_order', '<f8'), ('word_mail', '<f8'), ('word_receive', '<f8'), ('word_will', '<f8'), ('word_people', '<f8'), ('word_report', '<f8'), ('word_addresses', '<f8'), ('word_free', '<f8'), ('word_business', '<f8'), ('word_email', '<f8'), ('word_you', '<f8'), ('word_credit', '<f8'), ('word_your', '<f8'), ('word_font', '<f8'), ('word_000', '<f8'), ('word_money', '<f8'), ('word_hp', '<f8'), ('word_hpl', '<f8'), ('word_george', '<f8'), ('word_650', '<f8'), ('word_lab', '<f8'), ('word_labs', '<f8'), ('word_telnet', '<f8'), ('word_857', '<f8'), ('word_data', '<f8'), ('word_415', '<f8'), ('word_85', '<f8'), ('word_technology', '<f8'), ('word_1999', '<f8'), ('word_parts', '<f8'), ('word_pm', '<f8'), ('word_direct', '<f8'), ('word_cs', '<f8'), ('word_meeting', '<f8'), ('word_original', '<f8'), ('word_project', '<f8'), ('word_re', '<f8'), ('word_edu', '<f8'), ('word_table', '<f8'), ('word_conference', '<f8'), ('cap_ave', '<f8'), ('cap_long', '<i4'), ('cap_total', '<i4'), ('spam', '<i4')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks right. I also check the **spam rate** in this data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.394"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(data['spam']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target vector and feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **target vector** is the last column of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **feature matrix**, I convert the resulting subarray to an **unstructured array**, leaving aside the last column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[list(data.dtype.names[:-1])]\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "X = structured_to_unstructured(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of this matrix is as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 51)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop a tree decision classifier, I use the **estimator class** `DecisionTreeClassifier` from the scikit-learn subpackage `tree`. This is imported as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I instantiate a first estimator from this class. I set `max_depth=2`, which limits the **depth**, that is, the length of the longest branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf1 = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `fit` finds the optimal tree under this specification. This tree can be seen at `github.com/cinnData/MLearning/blob/main/7.%20Decision%20trees/fig 7.2.png`. I has four leaves and uses only three of the 51 features available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `score` gives us the **accuracy** of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.834"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(treeclf1.score(X, y), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this is a not case of **class imbalance**, the accuracy is not appropriate for the evaluation of this model, by different reasons. Let me postpone the discussion to the end of the exmaple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the **confusion matrix**. First, I obtain the predicted target values with the method `predict`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = treeclf1.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix resulting from cross tabulating `y` and `ypred1`. It can be obtained by means of the method `confusion_matrix`, from the subpackage `metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2575,  213],\n",
       "       [ 549, 1264]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf1 = confusion_matrix(y, ypred1)\n",
    "conf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **true positive rate** and the **false positive rate** can be extracted from this matrix (also calculated directly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.697, 0.076)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1 = conf1[1, 1]/np.sum(conf1[1, :])\n",
    "fp1 = conf1[0, 1]/np.sum(conf1[0, :])\n",
    "round(tp1, 3), round(fp1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weakest point of this model is the false positive rate, which is a bit too high. But it is a small tree, so let us see whether further branching can improve these statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A deeper tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try next a tree with `max_depth=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf2 = DecisionTreeClassifier(max_depth=3)\n",
    "treeclf2.fit(X, y)\n",
    "round(treeclf2.score(X, y), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has clearly improved. The new confusion matrix is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2598,  190],\n",
       "       [ 406, 1407]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred2 = treeclf2.predict(X)\n",
    "conf2 = confusion_matrix(y, ypred2)\n",
    "conf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true positive and false positive rates both improve, though the second one is still a bit high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.776, 0.068)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp2 = conf2[1, 1]/np.sum(conf2[1, :])\n",
    "fp2 = conf2[0, 1]/np.sum(conf2[0, :])\n",
    "tp2.round(3), fp2.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set now `max_depth=4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.891"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf3 = DecisionTreeClassifier(max_depth=4)\n",
    "treeclf3.fit(X, y)\n",
    "round(treeclf3.score(X, y), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is still improving. Let us take a look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2627,  161],\n",
       "       [ 341, 1472]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred3 = treeclf3.predict(X)\n",
    "conf3 = confusion_matrix(y, ypred3)\n",
    "conf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.812, 0.058)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp3 = conf3[1, 1]/np.sum(conf3[1, :])\n",
    "fp3 = conf3[0, 1]/np.sum(conf3[0, :])\n",
    "round(tp3, 3), round(fp3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me close the example with a final model, based on a deeper tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set now `max_depth=5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf4 = DecisionTreeClassifier(max_depth=5)\n",
    "treeclf4.fit(X, y)\n",
    "round(treeclf4.score(X, y), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy still improves a bit. The confusion matrix is, now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2696,   92],\n",
       "       [ 350, 1463]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred4 = treeclf4.predict(X)\n",
    "conf4 = confusion_matrix(y, ypred4)\n",
    "conf4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find an interesting decrease in the number of false positives, which is relevant for his example. The false positive rate confirms this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.807, 0.033)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp4 = conf4[1, 1]/np.sum(conf4[1, :])\n",
    "fp4 = conf4[0, 1]/np.sum(conf4[0, :])\n",
    "round(tp4, 3), round(fp4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I got stuck with the positive rate, the false positive rate is promising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most attractive traits of decision trees is that they produce, as a by-product, a ranking of the features by their contribution to the predictive power of the model. This is extracted by the method `feature_importances_`, which returns a 1d array in which every term is the **importance** of one of the features, measured as the **percentage of reduction of the impurity** due to the splits in which the feature is involved. A null value indicates that the corresponding feature is not involved in any split, so it is not used by the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = treeclf4.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our biggest tree uses 15 features, out from 51. This is not surprising, since this is maximum number of features that a tree obtained under the specification `max_depth=4` can use. These features can be listed in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = np.array(data.dtype.names[:-1])[imp > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = np.round(treeclf4.feature_importances_[imp > 0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A report can be extracted with NumPy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['word_remove', 0.406],\n",
       "       ['word_free', 0.233],\n",
       "       ['word_money', 0.108],\n",
       "       ['word_000', 0.057],\n",
       "       ['cap_ave', 0.052],\n",
       "       ['word_george', 0.041],\n",
       "       ['word_hp', 0.039],\n",
       "       ['word_edu', 0.033],\n",
       "       ['word_internet', 0.009],\n",
       "       ['cap_long', 0.005],\n",
       "       ['word_mail', 0.005],\n",
       "       ['word_our', 0.004],\n",
       "       ['word_650', 0.003],\n",
       "       ['word_hpl', 0.003],\n",
       "       ['cap_total', 0.002],\n",
       "       ['word_technology', 0.001]], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_report = np.array([feat_list, feat_imp], dtype=object).transpose()\n",
    "feat_report[np.argsort(np.array(feat_report[:, 1], dtype='float'))[::-1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't pay too much attention at the trick which I applied to extract the list sorted by the importance. These are NumPy technicalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This example shows how the predictions can be improved by increasing the **model complexity**. In the decision trees, the complexity is visualized as the tree getting more branches, so producing a finer partition of the data set into leaf nodes.\n",
    "\n",
    "* Even if you do not see the improvement halting at a certain degree of complexity, you must be cautious, because, in machine learning, complexity comes hand in hand with **overfitting**: when our model becomes too well adapted to the training data, it does not achieve the same performance with fresh data, not used to develop the model. How to deal with overfitting will be seen later in this course.\n",
    "\n",
    "* The data set of this example is not a \"representative sample of a population\". The spam rate is not the one Hewlett-Packard was finding in real operations, but an artificial one. So you must be careful when extrapolating the results obtained. Any calculation involving the two columns of the confusion matrix, that is, mixing spam with non-spam, is suspicious. The accuracy is an example. The true accuracy should be estimated as the weighted average of the accuracy in the spam subpopulation and the accuracy in the non-spam subpopulation. But we don't know how to weight these two things. \n",
    "\n",
    "* On the other hand, as far as we can reproduce them in some **test data**, the true positive and false positive rates can be trusted, since they are calculated separately, in the spam and the non-spam part, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop the three `cap_` variables and **binarize** all the `word_` variables, transforming them into dummies for the occurrence of the corresponding word. Develop two spam classifiers, one based on a **logistic regression** equation and the other one based on a **decision tree**, using the binarized data set.\n",
    "\n",
    "2. Evaluate these classifiers based on their respective **confusion matrices**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
