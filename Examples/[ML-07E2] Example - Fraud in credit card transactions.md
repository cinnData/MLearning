# [ML-07E2] Example - Fraud in credit card transactions

## Introduction

**Payment card fraud** is a major challenge for business, causing substantial financial losses. According to the 2019 Nilson Report, card fraud losses worldwide increased from 9.84 billion dollars in 2011 to 27.85 billion dollars in 2018, and are forecasted to reach more than 40 billion dollars in 2027. Nevertheless, card fraud in Europe declined notably in 2021 amid the implementation of regulatory measures, according to the last report from the European Central Bank.

Detecting **fraud patterns** in payment card transactions is very difficult. With the ever-growing amount of data generated by payment card transactions, it has become impossible for a human analyst to detect fraud patterns in **transaction data sets**. It is a cat and mouse game, where fraud patterns change over time. As technology evolves, both in terms of fraud prevention and ease of use of payment systems, so do fraudsters' techniques. They adapt by moving from the old targets to the vulnerabilities of the new technologies. They also benefit from the constant changes in volume and characteristics of genuine transactions. As a result, card fraud detection has increasingly focused on **machine learning** (ML) techniques, in order to automate the process of identifying fraud patterns from large volumes of data.

Effective fraud detection requires a mix of **automated systems** and **fraud investigators**. This has non-trivial methodological implications. First, automated systems should optimize the workload of the investigators. Second, they work at different time scales: while an automated system provides a risk score for a transaction in less than a second, an investigation requires contacting a client to confirm a fraud, which can take days, or weeks.

It is useful to distinguish two transaction scenarios:

* In **card-present** (CP) scenarios, such as transactions at a **point-of-sale** (POS) or at an **automated teller machine** (ATM), a physical card is needed. In this setting, the fraud typologies are: (a) *lost or stolen card*, (b) *counterfeited card*, and (c) *card not received* (intercepted by a fraudster).

* In **card-not-present** (CNP) scenarios, the payment is performed on the Internet, by phone, or by mail, so the physical card is not required. Most CNP frauds come from illegally obtained payment credentials (*e.g*. card numbers), either from data breaches or directly from the cardholders (*e.g*. via phishing). Such credentials are usually not used directly, but rather put on sale on underground web marketplaces and later used by criminal groups. Criminals who steal data are usually not the same as those who perpetrate frauds. The data involved in CNP fraud are usually the card number, card expiration date, card security code, and personal billing information.

Fraudsters are recently more likely to exploit the deficiencies of CNP scenarios than those of CP ones, probably because CP scenarios have existed for more than two decades now, and have become pretty robust to fraud attacks, thanks to the technology of **chip-embedded cards**. Also, physical barriers can often help to prevent CP frauds. As stated in the 2019 Nilson report, CNP scenarios accounted for 54% of all losses to fraud for the year 2018, but only for less than 15% of all purchase volume worldwide (CNP+POS+ATM). The proportion of CNP fraud is even higher in Europe, a 79%, according to the 2020 report on card fraud of the European Central Bank.

A credit card fraud detection system is typically composed of five layers of control:

1. **Terminal**. Security checks include the PIN code, the number of attempts, the card status (active/blocked), the balance available, and the expenditure limit. These operations are performed in real-time by querying a server of the card-issuing company. Requests that do not pass any of these controls are denied, while the others are processed by the second layer of control.

2. **Transaction-blocking rules** are if-then-else statements meant to block suspected requests. They use the information available when the payment is requested, without analyzing historical records or cardholder profiles. An example of a blocking rule could be *IF internet transaction AND unsecured website THEN deny*. In practice, several blocking rules are simultaneously applied, and transactions firing any of these rules are blocked (but cards not deactivated). Blocking rules are **expert-driven**, manually designed by investigators. To guarantee real-time operations and avoid blocking many genuine transactions, they must be quick to compute and very precise, raising very few false alarms. Transactions passing the blocking rules are authorized, though the fraud detection activity continues after having enriched transaction data with aggregated features to contextualize the current purchase with respect to the previous ones and the cardholder profile. These aggregated features can be the mean expenditure, the average number of transactions in the same day, the location of the previous purchases, etc. This is called **feature engineering**. Aggregated features and current transaction data are stacked in a feature vector, on which the next layers of the system operate.

3. **Scoring rules** are also expert-driven. They are expressed as if-then-else statements, which assign a score to each authorized transaction. Scoring rules are manually designed by investigators, who arbitrarily define their scores. An example of a scoring rule can be *IF previous transaction in a different continent AND less than one hour from the previous transaction THEN fraud score = 0.95*. Unfortunately, scoring rules can detect only previously discovered fraud strategies, with patterns involving a few features. Moreover, they are rather subjective, and they can be incomplete and difficult to maintain.

4. A **data-driven model** based on a classifier which estimates the **probability** for each transaction to be a fraud. This probability is used as the **fraud score** associated with the transaction. This model is trained on a set of labeled transactions and cannot be interpreted or manually modified by investigators. An effective data-driven model is expected to detect fraud patterns from multiple features, according to rules that may go beyond investigator experience, and that do not necessarily correspond to interpretable rules.

5. **Investigators** are experienced in analyzing credit card transactions. They design blocking and scoring rules. They are also in charge of controlling the alerts raised by the scoring rules and the data-driven model, to determine whether these correspond to frauds or to false alarms. They call cardholders and, after having verified, assign the label "genuine" or "fraud" to the alerted transaction. Any suspected card is immediately blocked. Typically, investigators check all the recent transactions from a compromised card, which means that each detected fraud can potentially generate more than one feedback. In a real-world fraud detection system, investigators can only check few alerts per day, as this process can be long and tedious. Therefore, the primary goal of a data-driven model is to return precise alerts.

The effective application of ML methods to card fraud data present some specific challenges:

* **Class imbalance**. Transaction data contain much more legitimate than fraudulent transactions. The **fraud rate** in real-world data is typically under 1%. Learning from imbalanced data is a difficult task since most learning algorithms do not handle well large differences between classes. Dealing with class imbalance requires the use of specific learning strategies, a topic known as **imbalanced learning**.

* **Concept drift**. Transaction and fraud patterns change. First, the spending habits of credit card users are different during weekdays, weekends and vacation periods, and evolve over time. Also, fraudsters adopt new techniques as the old ones become obsolete. This requires learning strategies that can cope with temporal changes in statistical distributions, a topic known as **online learning**. 

* **Near real-time requirements**. Fraud detection systems must be able to quickly detect fraud transactions. Given the potentially high volume of transaction data, classification times in the millisecond scale may be required. This relates to the parallelization and scalability of fraud detection systems.

* **Sequential modeling**. Each terminal and/or customer generates a stream of sequential data with unique characteristics. An important challenge of fraud detection consists in modeling these streams to detect abnormal behaviors. Modeling may be done by aggregating features over time, or by relying on sequential prediction models such as **recurrent neural networks**.

* **Class overlap**. With only raw information about a transaction, distinguishing between a fraudulent and a genuine transaction is close to impossible. This is commonly addressed with feature engineering techniques, which add contextual information to raw payment information.

* **Performance measures**. Standard measures for classification models, such as the **accuracy** or the **AUC ROC**, are not well suited for detection problems, due to class imbalance and the complex cost structure of fraud detection. It is often necessary to consider multiple measures to assess the overall performance of a fraud detection system. Despite its central role in the design of a fraud detection system, there is currently no consensus on the performance measures to be used.

* **Lack of public datasets**. For confidentiality reasons, real-world credit card transactions cannot be publicly shared. There exist a few publicly shared data sets, with limitations such as **obfuscated features** and short time scope. The scarcity of data sets for fraud detection is partly remedied with **simulated data**.

## The data set

In credit card fraud detection, data typically consist of transaction data, collected for example by a payment processor or a bank. Transaction data can be divided into three groups:

* **Account-related features**: account number, date of account opening, card limit, expiry date, etc.

* **Transaction-related features**: transaction reference number, account number, transaction amount, terminal number, transaction time, etc. 

* **Customer-related features**: customer number, type of customer (*e.g*. low/high profile), etc.

This example uses a simulated data set, generated in two steps, starting with a set of a few basic features and enlarging it with some feature engineering. In the first step, 1,475,853 transactions were generated for the period from April 30th to September 30th (22 complete weeks). The initial features are:

* `TRANSACTION_ID`, a unique identifier of the transaction.

* `TX_DATETIME`, date and time at which the transaction occurs, as 'yyyy-mm-dd hh:mm:ss'.

* `CUSTOMER_ID`, a unique customer identifier.

* `TERMINAL_ID`, a unique terminal identifier.

* `TX_AMOUNT`, the transaction amount, in euros.

* `TX_FRAUD`, a dummy feature (1/0) for the transaction to be a fraud.

This initial data set contains 13,081 (0.89%) fraud transactions, a realistic degree of class imbalance. Some additional features were added:

* `TX_DURING_WEEKEND`, a dummy for the transaction taking place during the weekend.

* `TX_DURING_NIGHT`, a dummy for the transaction taking place during the night.

* `CUSTOMER_ID_NB_TX_1DAY_WINDOW`, number of transactions by the customer in that day.

* `CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW`, average spending amount by the customer in that day.

* `CUSTOMER_ID_NB_TX_7DAY_WINDOW`, number of transactions by the customer in the last 7 days.

* `CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW`, average spending amount by the customer in the last 7 days.

* `CUSTOMER_ID_NB_TX_30DAY_WINDOW`, number of transactions by the customer in the last 30 days.

* `CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW`, average spending amount by the customer in the last 30 days.

* `TERMINAL_ID_NB_TX_1DAY_WINDOW`, number of transactions on the terminal in the last 8 days.

* `TERMINAL_ID_RISK_1DAY_WINDOW`, average number of frauds on the terminal in the last 8 days.

* `TERMINAL_ID_NB_TX_7DAY_WINDOW`, number of transactions on the terminal in the last 14 days.

* `TERMINAL_ID_RISK_7DAY_WINDOW`, average number of frauds on the terminal in the last 14 days.

* `TERMINAL_ID_NB_TX_30DAY_WINDOW`, number of transactions on the terminal in the last 30 days.

* `TERMINAL_ID_RISK_30DAY_WINDOW`, average number of frauds on the terminal in the last 30 days.

The data set comes in five zipped CSV files, one for each month:  `fraud_may.csv.zip`, `fraud_jun.csv.zip`,  `fraud_jul.csv.zip`,  `fraud_aug.csv.zip` and  `fraud_sep.csv.zip`.

Source: YA Le Borgne, W Siblini, B Lebichot & G Bontempi (2022), *Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook*, Université Libre de Bruxelles. April data have been discarded, to get a set of complete weeks covering five months. 

## Questions

Q1. Take the column `TX_FRAUD` as the target and select an appropriate set of features for predicting this target. Pick the first week as the **training period**, the second week as the **delay period** and the third week as the **testing period**.

Q2. Train a **logistic regression model** using the data of the training period, and test it using the data of the test period. For testing, use the **precision top-100**. Assuming that you can inspect only 100 transactions every day, pick those 100 transactions based on your model. The precision top-100 is the percentage of the transactions inspected that are effectively fraudulent.

Q3. Test your model using the **card precision top-100**. Assume that: (a) you can inspect only 100 customers every day, and (b) if at least one transaction from a customer is suspected, all the transactions of that customer in that day are going to be inspected. Pick those 100 customers based on your model. The card precision top-100 is the percentage of the customers inspected that effectively have at least one fraudulent transaction.

Q4. Complete the testing of questions Q2 and Q3 by comparing, for every day, the number of fraud transactions and fraud cards with the numbers effectively inspected.

Q5. The data set covers 22 complete weeks, so you can perform this analysis 20 times. The first training period would start on Monday April 30th and the first test period on Monday May 14th. The last training period would start on Monday September 10th and the last test period on Monday September 24th. Is the performance of your model be consistent across weeks? 
