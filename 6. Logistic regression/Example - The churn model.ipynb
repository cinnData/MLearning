{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - The churn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term **churn** is used in marketing to refer to a customer leaving the company in favour of a competitor. Churning is a common concern of **Customer Relationship Management** (CRM). A key step in proactive churn management is to predict whether a customer is likely to churn, since an early detection of the potential churners helps to plan the retention campaigns.\n",
    "\n",
    "In this example, I develop a churn model, based on a **logistic regression equation**, for a company called *Omicron Mobile*, which provides mobile phone services. The data set is based on a random sample of 5,000 customers whose accounts were still alive by September 30, and have been monitored during the fourth quarter. 968 of those customers churned during the fourth quarter, a **churning rate** of 19.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables included in the data set are: \n",
    "\n",
    "* `id`, a customer ID (the phone number).\n",
    "\n",
    "* `aclentgh`, the number of days the account has been active at the beginning of the period monitored.\n",
    "\n",
    "* `intplan`, a dummy for having an international plan.\n",
    "\n",
    "* `dataplan`, a dummy for having a data plan.\n",
    "\n",
    "* `ommin`, the total minutes call to any Omicron mobile phone number, voicemail or national landline.\n",
    "\n",
    "* `omcall`, the total number of calls to any Omicron mobile phone number, voicemail or national landline.\n",
    "\n",
    "* `otmin`, the total minutes call to other mobile networks.\n",
    "\n",
    "* `otcall`, the total number of calls to other networks.\n",
    "\n",
    "* `ngmin`, the total minutes call to nongeographic numbers. Nongeographic numbers, such as UK 0844 or 0871 numbers, are often helplines for organizations like banks, insurance companies, utilities and charities. \n",
    "\n",
    "* `ngcall`, the total number of calls to nongeographic numbers.\n",
    "\n",
    "* `imin`, the total minutes in international calls.\n",
    "\n",
    "* `icall`, the total international calls.\n",
    "\n",
    "* `cuscall`, the number of calls to customer service.\n",
    "\n",
    "* `churn`, a dummy for churning.\n",
    "\n",
    "All the data are from the third quarter except the last variable. \n",
    "\n",
    "*Source*. MA Canela, I Alegre & A Ibarra (2019), *Quantitative Methods for Management*, Wiley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in other examples, I import the data from a remote CSV file, to a structured NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/cinnData/MLearning/main/6.%20Logistic%20regression/'\n",
    "fname = path + 'churn.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(fname, delimiter=',', names=True, dtype=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of samples is 5,000, as explained in the description of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first rows are as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('409-8978',  77, 0, 0,  80.8, 70, 165.9,  67, 18.6,  6,  9.5, 4, 1, 0),\n",
       "       ('444-7077', 105, 0, 0, 131.8, 66, 131.7, 105,  5.1,  6,  6.7, 2, 0, 0),\n",
       "       ('401-9132', 121, 0, 1, 212.1, 57, 195.4, 140, 14.9, 14, 28.6, 8, 1, 0),\n",
       "       ('409-2971', 115, 0, 0, 186.1, 64, 230.9, 125, 26.5, 16,  9.9, 4, 1, 0),\n",
       "       ('431-5175', 133, 0, 1, 166.5, 61, 176. ,  74, 36.1, 11,  5.3, 2, 1, 0)],\n",
       "      dtype=[('id', '<U8'), ('aclength', '<i8'), ('intplan', '<i8'), ('dataplan', '<i8'), ('ommin', '<f8'), ('omcall', '<i8'), ('otmin', '<f8'), ('otcall', '<i8'), ('ngmin', '<f8'), ('ngcall', '<i8'), ('imin', '<f8'), ('icall', '<i8'), ('cuscall', '<i8'), ('churn', '<i8')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last column, which can be extracted as `data['churn']`, is a dummy, so the mean will give us the proportion of churners, the churning rate. This also agrees with our expectations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.194"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(data['churn']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target vector and feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **target vector** is the last column of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **feature matrix**, I create first a structured subarray dropping the first and the last columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[list(data.dtype.names[1:-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I convert the structured array `X` to an **unstructured array*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "X = structured_to_unstructured(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me check that `X` has the right shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target vector `y` and the feature matrix `X` are ready. Now, we develop a logistic regression model to predict `y` from `X`, using the estimator class `LogisticRegression`, from the scikit-learn subpackage `linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I instantiate a logistic regression estimator, calling it `logclf` (you can give it any name). Instead of accepting the default arguments, as I did in the linear regression example, I increase the **maximum number of interations**, whose default is 100, to 1,000. I leave the discussion of this point for the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logclf = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `fit` works as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a classification model, the method `score` returns the **accuracy**, which is the proportion of right prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logclf.score(X, y).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may look like an achievement, but it is not, since the data show **class imbalance**. With only 19.4% positive cases, 80.6% accuracy can be obtained in a trivial way. Let us take a closer look at what at the performance of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As given by the method `predict`, the predicted target values are obtained as follows:\n",
    "\n",
    "* A **class probability** is calculated for each target value. In this example, this means two complementary probabilities, one for churning (`churn=1`) and one for not churning (`churn=0`). These probabilities can be extracted with the method `predict_proba` (see below).\n",
    "\n",
    "* For every sample, the predicted target value is the one with higher probability.\n",
    "\n",
    "For binary classification, this can also be described in terms of predictive scores and cutoff values. The **predictive score** is the probability of the positive class (churning). The predicted target value is positive when the score exceeds the **cutoff** and negative otherwise. The default cutoff is 0.5.\n",
    "\n",
    "This alternative approach gives us room for changing the cutoff. This is better understood after an exploration of the scores. We can extract them, as a 1d array, with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = logclf.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind that Python orders the target values alphabetically. This means that the negative class (`churn=0`) comes first. So, to get the scores, which are the probabilities of the positive class, I have selected the second column of the 2d array returned by `logclf.predict_proba`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the predictive scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the distribution of the predictive scores through a histogram. In this case, I am going to plot separately the scores for the churners (968) and the non-churners (4032) groups.\n",
    "\n",
    "I import `pyplot`as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see below the code to plot the two histograms, side-by-side. The `plt.figure` line specifies the total size of the figure. Then, `plt.subplot(1, 2, 1)` and `plt.subplot(1, 2, 2)` establish two sections in the code, one for each subplot. These sections are easy to read after our previous experience with histograms. The `range` argument is used to get intervals of length 0.1, which are easier to read.\n",
    "\n",
    "Note that `plt.subplot(1, 2, i)` refers to the `i`-th subplot in a grid of one row and two columns. The subplots are ordered by row, from left to righ and from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (14,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(scores[y == 1], range=(0,1), color='gray', rwidth=0.96)\n",
    "plt.title('Figure a. Scores (Churners)')\n",
    "plt.xlabel('Churn score')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(scores[y == 0], range=(0,1), color='gray', rwidth=0.96)\n",
    "plt.title('Figure b. Scores (non-churners)')\n",
    "plt.xlabel('Churn score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now imagine the cutoff as a vertical line, and move it, right or left of the default value 0.5. Samples falling on the right of the vertical line would be classified as positive. Those falling on the left, as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The default cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default cutoff, used by the method `predict`, is 0.5. So, the predicted values for this cutoff are obtained as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = logclf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is plainly seen, in Figure a, that with this cutoff we miss more than one half of the churners. So, in spite of the accuracy, our model would not be adequate for a business application.\n",
    "\n",
    "The **confusion matrix** resulting from the cross tabulation of the actual and the predicted target values, will confirm this visual intuition. Confusion matrices can be obtained in many ways. For instance, with the function `confusion_matrix` of the scikit-learn subpackage `metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3896,  136],\n",
       "       [ 655,  313]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy returned by the method `logclf.score` is the sum of the diagonal terms of this matrix divided by the sum of all terms of the matrix. It can also calculated directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == ypred).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we guessed from the histogram, our churn model is not capturing enough churners (304/968) for a business application. Let us try a different one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A lower cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict more positive, we have to lower the cutoff. Figure a suggests that we have to go down to about 0.2 make a real difference. But Figure b warns us against lowering it further. So, I will try 0.2. The new vector of predicted target values is then obtained as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = (scores > 0.2).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new confusion matrix is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3166,  866],\n",
       "       [ 344,  624]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we are capturing about 2/3 of the churners. This comes at the price of raising the false positives to 866, which affects the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == ypred).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clear way to summarize the evaluation of the model comes through the true positive and false positive rates. They can be extracted from the confusion matrix or calculated directly. The **true postive rate** is the proportion of true positives among the actual positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ypred[y == 1]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **false positive rate** is the proportion of false positives among the actual negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.215"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ypred[y == 0]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There is no formula to calculate the coefficients of a logistic regression, as it happens with linear regression. So, the best thing you can get is an approximation to the optimal coefficients by means of an iterative method, which is called the **solver**. There are many options for the solver, and I have used here the scikit-learn default, to make it simple. But it turns out that the default number of iterations is not enough in many cases and you get a warning from Python. To grasp this point, try different values for `max_iter` in the specification of the logistic regression estimator. Examine how the number of iterations affects the accuracy of the classifier.\n",
    "\n",
    "2. Assume that the Omicron management plans to offer a 20% discount to the customers that the model classifies as potential churners, and that this offer is going to have a 100% success, so the company will retain all the churners detected. Evaluate the benefit produced by this retention policy with the two models presented here.\n",
    "\n",
    "3. Define a Python function which gives the benefit in terms of the cutoff and find an optimal cutoff for this retention policy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
