{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - The spam filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **spam filter** is an algorithm which classifies e-mail messages as either spam or non-spam, based on a collection of **numeric features** such as the frequency of certain words or characters. In a spam filter, the **false positive rate**, that is, the proportion of non-spam messages wrongly classified as spam, must be very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `spam.csv` contains data on 4,601 e-mail messages. Among these messages, 1,813 have been classified as spam. The data were gathered at Hewlett-Packard by merging: (a) a collection of spam e-mail from the company postmaster and the individuals who had filed spam, and (b) a collection of non-spam e-mail, extracted from filed work and personal e-mail.\n",
    "\n",
    "The variables are:\n",
    "\n",
    "* 48 numeric features whose names start with `word_`, followed by a word. They indicate the frequency, in percentage scale, with which that word appears in the message. Example: for a particular message, a value 0.21 for `word_make` means that 0.21% of the words in the message match the word 'make'.\n",
    "\n",
    "* 3 numeric features indicating, respectively, the average length of uninterrupted sequences of capital letters (`cap_ave`), the length of the longest uninterrupted sequence of capital letters (`cap_long`) and the total number of capital letters in the message (`cap_total`).\n",
    "\n",
    "* A dummy indicating whether that e-mail message is spam (`spam`).\n",
    "\n",
    "Source: Hewlett-Packard. Taken from T Hastie, R Tibshirani & JH Friedman (2001), *The Elements of Statistical Learning*, Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.recfromcsv('spam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(0., 0.64, 0.64, 0., 0.32, 0., 0., 0., 0., 0., 0., 0.64, 0., 0., 0., 0.32, 0., 1.29, 1.93, 0., 0.96, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3.756, 61, 278, 1)],\n",
       "          dtype=[('word_make', '<f8'), ('word_address', '<f8'), ('word_all', '<f8'), ('word_3d', '<f8'), ('word_our', '<f8'), ('word_over', '<f8'), ('word_remove', '<f8'), ('word_internet', '<f8'), ('word_order', '<f8'), ('word_mail', '<f8'), ('word_receive', '<f8'), ('word_will', '<f8'), ('word_people', '<f8'), ('word_report', '<f8'), ('word_addresses', '<f8'), ('word_free', '<f8'), ('word_business', '<f8'), ('word_email', '<f8'), ('word_you', '<f8'), ('word_credit', '<f8'), ('word_your', '<f8'), ('word_font', '<f8'), ('word_000', '<f8'), ('word_money', '<f8'), ('word_hp', '<f8'), ('word_hpl', '<f8'), ('word_george', '<f8'), ('word_650', '<f8'), ('word_lab', '<f8'), ('word_labs', '<f8'), ('word_telnet', '<f8'), ('word_857', '<f8'), ('word_data', '<f8'), ('word_415', '<f8'), ('word_85', '<f8'), ('word_technology', '<f8'), ('word_1999', '<f8'), ('word_parts', '<f8'), ('word_pm', '<f8'), ('word_direct', '<f8'), ('word_cs', '<f8'), ('word_meeting', '<f8'), ('word_original', '<f8'), ('word_project', '<f8'), ('word_re', '<f8'), ('word_edu', '<f8'), ('word_table', '<f8'), ('word_conference', '<f8'), ('cap_ave', '<f8'), ('cap_long', '<i8'), ('cap_total', '<i8'), ('spam', '<i8')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the spam rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.394"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(data['spam']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target vector and feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the feature matrix. We drop the last column, converting the resulting recarray to an unstructured array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[list(data.dtype.names[:-1])]\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "X = structured_to_unstructured(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the **estimator class** `DecisionTreeClassifier` from the scikit-learn subpackage `tree`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an estimator from this class. The argument `max_depth=2` limits the length of the longest branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf1 = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we **fit** the estimator `treeclf1` to the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **accuracy** of this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.834"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(treeclf1.score(X, y), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A finer screening can be performed on the **confusion matrix**. First, we obtain the predicted target values with the method `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = treeclf1.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is obtained by means of the method `confusion_matrix`, from the subpackage `metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2575,  213],\n",
       "       [ 549, 1264]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf1 = confusion_matrix(y, ypred1)\n",
    "conf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positive and false positive rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.697, 0.076)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1 = conf1[1, 1]/sum(conf1[1, :])\n",
    "fp1 = conf1[0, 1]/sum(conf1[0, :])\n",
    "round(tp1, 3), round(fp1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weakest point is the false positive rate, that is, the proportion of legal messages classified as spam, which is a bit too high.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A deeper tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try next a tree with `max_depth=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8704629428385133"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf2 = DecisionTreeClassifier(max_depth=3)\n",
    "treeclf2.fit(X, y)\n",
    "treeclf2.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is improved. The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2598,  190],\n",
       "       [ 406, 1407]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred2 = treeclf2.predict(X)\n",
    "conf2 = confusion_matrix(y, ypred2)\n",
    "conf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positive and false positive rates both improve, though the second one is still a bit high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.776, 0.068)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp2 = conf2[1, 1]/sum(conf2[1, :])\n",
    "fp2 = conf2[0, 1]/sum(conf2[0, :])\n",
    "round(tp2, 3), round(fp2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set now `max_depth=4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8908932840686807"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf3 = DecisionTreeClassifier(max_depth=4)\n",
    "treeclf3.fit(X, y)\n",
    "treeclf3.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2627,  161],\n",
       "       [ 341, 1472]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred3 = treeclf3.predict(X)\n",
    "conf3 = confusion_matrix(y, ypred3)\n",
    "conf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.812, 0.058)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp3 = conf3[1, 1]/sum(conf3[1, :])\n",
    "fp3 = conf3[0, 1]/sum(conf3[0, :])\n",
    "round(tp3, 3), round(fp3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9039339274070854"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf4 = DecisionTreeClassifier(max_depth=5)\n",
    "treeclf4.fit(X, y)\n",
    "treeclf4.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2696,   92],\n",
       "       [ 350, 1463]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred4 = treeclf4.predict(X)\n",
    "conf4 = confusion_matrix(y, ypred4)\n",
    "conf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.807, 0.033)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp4 = conf4[1, 1]/sum(conf4[1, :])\n",
    "fp4 = conf4[0, 1]/sum(conf4[0, :])\n",
    "round(tp4, 3), round(fp4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got stuck with the positive rate, but the false positive rate is promising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.00428051,\n",
       "       0.        , 0.40565322, 0.00866955, 0.        , 0.00535017,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.23255608, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05686147, 0.1077894 , 0.04113833,\n",
       "       0.        , 0.04083541, 0.00327628, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0013128 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03341536, 0.        , 0.        , 0.05179166, 0.00463312,\n",
       "       0.00243665])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf4.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features used by the tree are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(data.dtype.names[:-1])[treeclf4.feature_importances_ > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.round(treeclf4.feature_importances_[treeclf4.feature_importances_ > 0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['word_our', 0.004],\n",
       "       ['word_remove', 0.406],\n",
       "       ['word_internet', 0.009],\n",
       "       ['word_mail', 0.005],\n",
       "       ['word_free', 0.233],\n",
       "       ['word_000', 0.057],\n",
       "       ['word_money', 0.108],\n",
       "       ['word_hp', 0.041],\n",
       "       ['word_george', 0.041],\n",
       "       ['word_650', 0.003],\n",
       "       ['word_technology', 0.001],\n",
       "       ['word_edu', 0.033],\n",
       "       ['cap_ave', 0.052],\n",
       "       ['cap_long', 0.005],\n",
       "       ['cap_total', 0.002]], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([a, b], dtype=object).transpose()\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
